{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y8UYjjaYqQdm"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import time\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def timer(func): # timer using decorator\n",
        "  def wrapper(*args, **kwargs):\n",
        "    start_time = time.time()\n",
        "    result = func(*args, **kwargs)\n",
        "    end_time = time.time()\n",
        "    computation_time = end_time - start_time\n",
        "    print(f\"Execution time of {func.__name__}: {computation_time} seconds\")\n",
        "    return result\n",
        "  return wrapper"
      ],
      "metadata": {
        "id": "fwllrKrAra-l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_pickle('quiz_data.pkl')\n",
        "# print(data['x'][1])\n",
        "N = len(data['x'])\n",
        "idx = list(range(N))\n",
        "split_index = int(N * 0.8)\n",
        "\n",
        "train_idx = idx[:split_index]\n",
        "val_idx = idx[split_index:]\n",
        "\n",
        "x_train, y_train = data['x'][train_idx], data['y'][train_idx] #trainset과 trainset의 label생성\n",
        "x_val, y_val = data['x'][val_idx], data['y'][val_idx]"
      ],
      "metadata": {
        "id": "Ru0icmpMqa6d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create tensor at CPU #tensor는 3차원 이상의 자료구조(매트릭스 이상의)\n",
        "x_train_tensor = torch.as_tensor(data['x'])\n",
        "y_train_tensor = torch.as_tensor(data['y'])\n",
        "\n",
        "#create tensor at GPU\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "x_train_tensor = torch.as_tensor(x_train).to(device)\n",
        "y_train_tensor = torch.as_tensor(y_train).to(device)"
      ],
      "metadata": {
        "id": "vkOiJaA-tJXF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@timer\n",
        "def train_model_torch(lr=0.1, epochs=10):\n",
        "  b = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
        "  w = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
        "  mse_loss_sum = 0\n",
        "  for epoch in range(epochs):\n",
        "    #Loss computation\n",
        "    y_hat = b + w * x_train_tensor\n",
        "    error = (y_hat - y_train_tensor)\n",
        "    mse_loss = torch.mean(error ** 2)\n",
        "    mse_loss_sum += mse_loss\n",
        "    #gradient computation and descent\n",
        "    mse_loss.backward()\n",
        "    with torch.no_grad():\n",
        "      b -= lr * b.grad\n",
        "      w -= lr * w.grad\n",
        "    b.grad.zero_()\n",
        "    w.grad.zero_()\n",
        "    print(mse_loss_sum/epochs)\n",
        "  return w, b"
      ],
      "metadata": {
        "id": "cXhIt_AEqa4A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_model_torch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "uy8qZnSCqa84",
        "outputId": "33bdc8bf-9c49-49de-a9fd-fc2e41a805fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "UnboundLocalError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-61-03cb1ec0d2d0>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_model_torch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-2-ea674f970757>\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mcomputation_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mend_time\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-60-18d8ed662414>\u001b[0m in \u001b[0;36mtrain_model_torch\u001b[0;34m(lr, epochs)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my_hat\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my_train_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mmse_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mmse_loss_sum\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mmse_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;31m#gradient computation and descent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mmse_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'mse_loss_sum' referenced before assignment"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn, optim"
      ],
      "metadata": {
        "id": "yfq5u4yZur8F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@timer\n",
        "def train_model_optim(lr=0.1, epochs=10):\n",
        "  b = torch.randn(1, requires_grad=True, dtype=torch.float, device=device) #requires_grad means this param is\n",
        "  w = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
        "\n",
        "  parameters = [b, w]\n",
        "  optimizer = optim.SGD(parameters, lr = lr)\n",
        "  mse_loss = nn.MSELoss()\n",
        "  for epoch in range(epochs):\n",
        "    #Loss computation\n",
        "    y_hat = b + w * x_train_tensor\n",
        "    loss = mse_loss(y_hat, y_train_tensor)\n",
        "    #gradient computation and descent\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "  last_y_hat = b + w * x_train_tensor\n",
        "  last_error = (last_y_hat - y_train_tensor)\n",
        "  last_mse_loss = torch.mean(last_error ** 2)\n",
        "  print(last_mse_loss)\n",
        "\n",
        "\n",
        "  return w, b"
      ],
      "metadata": {
        "id": "Oiag_EUoqa_S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_w, train_b = train_model_optim()\n",
        "train_w, train_b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4mzzbRsqbBp",
        "outputId": "9d5c9309-7736-4c91-e23e-7931052cc52f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.3926, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
            "Execution time of train_model_optim: 0.00994110107421875 seconds\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([0.6934], requires_grad=True), tensor([-0.6829], requires_grad=True))"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XSblg5XOqbEL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}